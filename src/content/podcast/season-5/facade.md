---
title: The Façade of Control (Melody Kim)
season: 5
date: 2025-05-09
time: "46"
description: "Does technology give us control or the illusion of it? We explore how societal expectations, the nature of work, and AI challenge what it means to be human, contrasting the allure of self-sufficiency with the call to vulnerability."
episodeLink: https://anchor.fm/s/ff707650/podcast/play/102440505/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-4-9%2F3b4295ae-9b07-75cc-fdf4-475fb9781355.mp3
embedUrl: https://creators.spotify.com/pod/show/hopeinsource/episodes/The-Faade-of-Control-Melody-Kim-e32ko3p
sidebar:
  order: 2
---
### Links

### Transcript

> Edited this for ease of reading. [(edit)](https://github.com/hzoo/hopeinsource.com/blob/main/src/content/podcast/season-5/facade.md)

#### Intro

[00:00] **Melody:** We came into this saying we both didn't prepare a list of things to talk about, but maybe it'll make it more authentic. We only met not too long ago, randomly through Josh and then through the internet. It randomly popped up on your Twitter feed. The setup for this is great because I feel there's a lot I'm super curious about for you, and you don't know as much about me. There's a lot to unpack here.

[00:18] **Henry:** Oh, yes, that too. I randomly saw you on my feed.

[00:36] **Henry:** The mutual Twitter followers are really helpful. You know Nicole, you know Jeannie, all these people that I know, that helps it get going.

[00:45] **Melody:** Establish trust. And Nicole's been on the podcast before. On my end, what's super interesting to me about what you've been doing with Hope In Source is that I've generally explored the intersection of faith and technology and work. I moved here to New York in August after 10 years in San Francisco. During that time, I cultivated my community out there, but I always felt a little bit, I don't know if ostracized is the right word, but a feeling of not finding... If you did find someone at that intersection, you clung onto them. So we built this little community in the Bay. I didn't really have much exposure to that outside of that little community. When I saw that you had this whole podcast on this intersection, I found that super interesting. I still don't know the full story, and I feel even over lunch, I'm asking you more questions. But, there's a lot to talk about at the intersection of faith, technology, AI, building. The fact that you are doing your own thing and working on your own projects is also super fascinating. The creative process is something that I'm super interested in. Throw out some. Or the fact that even meeting you, this community exists in New York, and we still haven't met; we didn't cross paths before.

[02:29] **Henry:** That part is weird too. We all have that feeling of whether there are other people out there.

[02:34] **Melody:** You hope that the algo can take you there, but sometimes it doesn't.

#### Technology and Human Worth

[02:38] **Henry:** In the church setting, whether it's the leadership or people in church, they don't really get the intersection either. That's even true for people in tech. They don't even see it, especially with open source. And then, in tech, are people thinking about spiritual things maybe in a certain direction?

[02:51] **Melody:** That's a layer that's new to me, the whole open source part. It is curious why people are thinking about this more now. There are two things. One, at a macro or political or cultural level, there is a rightward shift, which I don't want to conflate Christianity with being a right-leaning person. But I feel lots of people are exploring. There is this swing towards religion, not just Christianity, but everything. That's one element. The other piece is this question of AI. It's interesting even talking to... I went home and was talking to some Korean elders, and the topic of AI came up. This was straight up a Korean ajusshi. He said, "And this is now begging the question of what does it mean to be human?" And I was, "Whoa." I didn't expect to be talking about this over fried chicken, you know what I mean? I feel AI is also bringing up that question of what is personhood and all this. And I feel that's where people are searching for answers. Is that faith? I don't know.

[04:18] **Henry:** It does challenge our default assumptions on what it means to be human, because maybe our society is such that to be human is about what we produce in our market-driven economy. If you're not increasing GDP or you're not able to make stuff, or there's something out there that's not a person that can make more or seems it can, better, faster, then what are we? You could say it's good because then it might lead someone, even myself, to think, oh, my worth and my being, it shouldn't necessarily be tied up in that?

[04:59] **Melody:** I haven't heard that one before. That our humanity for a long time, in the context of capitalism perhaps, has been tied to how much we're able to produce. And now that that's being taken away or challenged, what does it mean for us to be human?

#### Work Beyond the Title

[05:18] **Henry:** There's a huge psychological issue culturally around work. If you're not working, if you're unemployed, you're a loser. Just because you're not at a nine to five doesn't mean you're not doing anything for yourself, for your community, for God. It's-

[05:35] **Melody:** 100%. I love that, or this topic. It's been super top of mind because I've been talking about this with my girlfriends. There's this feeling that a lot of domestic labor has been devalued. You find people who would consider themselves feminists but then struggle with the idea of "I also enjoy sewing and things that would be traditionally seen as very trad wifey." There's this internal battle or challenge. My take is related to what you said: our view on work is that it's a job. Work is only when you are nine to five doing a laptop job. But someone at my church once said this to me. I mentioned to her, "Oh, and one day when I stop working..." She looked at me and said, "Melody, you never stop working." That was profound to me because it's true. The work we do for a community when we serve them, if we're preparing meals to go deliver to a sick friend, if we are visiting someone in the hospital, if we're doing work for our families at home, that's all work. The fact that we don't call it work devalues it and takes much away. We're tied to our value being when we have a full-time job, and that's not great for moms or people who take nontraditional paths. It's not helpful.

[07:36] **Henry:** Or even both of us right now. It comes down to if you don't have a name for it that's easy to understand. Is it legibility? It's not okay, and it's funny that that would prevent you from doing what you want. If you're in a good financial place to choose something different, you still don't because of the culture. When I first quit, I didn't get any money. Take a leap of faith. Maybe people will give me donations. I had a lot of people messaging me, and their tone is always very concerned. It's "Are you okay?" That made me second guess. I asked, "Am I okay?" Now it's been a long time, no one asks anymore, which is good. Or maybe it's in the back of their mind. Something that motivates me is the desire to pursue what's surprising.

#### Unpredictability and Decision Frameworks

[08:29] **Henry:** I want to tie that into faith. The American dream: go to a certain school, get a certain job, get married, have kids, retire, have a house, and then die. I'm still going to die. Why go through that route? There's almost a sense of adventure. The mystery of it can be appealing. It's also very scary.

[08:50] **Melody:** Would you say you're a very risk-tolerant person?

[08:56] **Henry:** I don't know if I would use that word. The point of options is to make a choice. That is a risk, because there's always opportunity cost if you use that framing. If I keep analyzing in a rationalist way, I would never do anything.

[09:11] **Melody:** The way I think about what you said is also that even if it's a predictable path, the reality is those steps aren't guaranteed either. It's a facade. Society tells you that you go to a good school, you get married, and you have kids. You get a good job, and actually, none of those things are guaranteed either. Maybe by taking this riskier path, we're being honest with how unpredictable life can be and that nothing's guaranteed. I feel there's a set of principles I operate off of, but I haven't written these down anywhere; I need to get to a point where I can do it. One is this idea that nothing is guaranteed—not the next hour, not the next day. People think I can be a little morbid by saying that, but how do we know we're going to be here next month? There's no guarantee that will be the case. My favorite decision-making framework is this idea: if you died in two years, because it has to be long term enough where you're not eating junk food every day, but also short term enough that it will challenge you to take maybe riskier or, to me, more aligned decisions with what you want. I use that frame to figure out what I want to do. It convinced me to move. That's how I made the decision to move out here. I don't know.

#### Allure of Control

[11:02] **Henry:** I can't help but bring up Ivan Illich, because his life inspires me and also his way of thinking as a Catholic historian.

[11:12] **Melody:** I haven't heard of him.

[11:13] **Henry:** He died in 2002. He uses a metaphor to talk about our technological society, its ability to control. It creates expectations on what we can do as individuals and society. That relates to your point about nothing is guaranteed, but technology makes us feel that way. As you said, it's facades. The more powerful our technology, the more facades we have. He contrasts two words: hope and expectation. Expectation is what technology gives us—predicting it's going to rain tomorrow, what child I'll have in the future, all these things you can predict. AI is all about prediction. My motivating factor is how to live in the present and not think of these fake ideals of the future, of this idealistic world, both in the past and the future.

[12:07] **Melody:** What do you mean by in the past?

[12:09] **Henry:** When things were good. You can't. We can learn from the past. Both of those lead you to the ends justify the means thinking. I will do whatever it takes to get to my ideal scenario. That's every single bad person, but they all have good intentions.

[12:26] **Melody:** I haven't really thought about it that way, but the way you framed technology, it gives us that idea that we can control things more and set more expectations. You mentioned AI in all of that. How do you feel AI is making us feel that way even more?

[12:49] **Henry:** At every level. Whenever I'm coding, I'm using it, and then I'm asking it questions about life or personal things. Where's the nuanced take? It's not all good, it's not all bad. I'd go back to the psychological effects of it, our dependence on it. I think of it more as outsourcing what we would normally ask someone, our friends or our family, to do; we ask AI to... Thinking more of a therapist and stuff like that. Pastoral questions. An inherent issue with AI is that it's not embodied, and that makes it lack something. You could say, once we have robots, then it'll fix it. But I don't know if that's even true. We'll see later, but... Now we'll give it one. And I'm saying, we think there's a fundamental difference between people. I don't want to be saying I feel that way, because there's something special about us.

#### Personhood

[13:35] **Melody:** But what would it fix? The fact that it's not embodied? Is that what they're saying? We've talked about this a little bit. When we were initially talking about doing the podcast, I recalled the Catholic Church had put out something like Antica e Nova, "The Catholic Church's Stance on AI." Generally, I've also been very curious about this question, even when AI was coming about, because everyone's scared of AGI and all this stuff. I feel there is a theological framework for how to think about personhood. The primary reason why we are created differently is because we're created in the image of God. A big part of that is our rationality. It's also our soul. AI is never going to have those things.

[14:52] **Henry:** How should we think about what it means to be created in the image of God? We say that a lot as Christians, and I don't know if we understand it ourselves, but also as a non-Christian, what does that even mean?

[15:00] **Melody:** I don't know. When I did a deep research query on this, I used AI to write this down. Meta. Let's see. I'm trying to... I don't know if I'll remember everything that came out from there, but I feel there's something about our intellect and rationality, and our soul; together, those two things combined are important. Maybe that was how they define intellect or something. When you think about AI, I think of that as knowledge that's devoid of the soul. Yes, AI can process knowledge at a greater throughput than any human can. But can it reason from a place that... the soul piece is what's missing, and that's what we... Being created in the image of God is very much the interaction of those things. It's also what differentiates us from animals. Again, I'm not the most well-versed in the exact philosophical framework here, but that's directionally accurate.

#### Self-Control

[16:18] **Henry:** When we talk about the fruit of the Spirit, one of the last ones is self-control. That is one thing that differentiates us from animals. The animal lives on instinct. If I'm hungry, I'm going to eat; I'm going to hunt for food. But we can suppress those desires, both for good and for bad. I think that has to do with what it means to be human. The example in the podcast I was listening to is God chooses to rest on the seventh day. That's an example of self-control. He doesn't have to keep creating; he stops. It wasn't for a practical reason. He thought it was good. And then Cain kills his brother out of anger, and in that moment, he was not able to exercise control and acted like an animal.

[16:59] **Melody:** An animalistic instinct. That's super interesting to me. What I've also heard, and again, I don't know if I'm going to explain it quite well, but humans have this ability to detach themselves from their current state and imagine a future state. I feel that adds to the self-control piece, where you can almost imagine what the consequences are for two hours from now or something.

#### Self-Perception

[17:26] **Henry:** It's funny because you could say that we're simulating, which is what an LLM does. Another side point would be that it's funny how our conception of who we are always seems to be based on whatever the latest thing that we've made. Now, people say, "Oh, we're an LLM." We have training, pre-training, all these things. The vocabulary we use to describe ourselves is whatever the latest thing we've made in our image, and that's funny. Before, we would use metaphors like wheels or the car or machine. It's funny that we keep changing our definition of who we are based on our latest thing, which I said is in our image. That says a lot.

[18:21] **Melody:** It is really interesting. I've heard that the tools shape the way that we think.

[18:28] **Henry:** Marshall McLuhan is another person I'm referencing. His book, *Understanding Media*, the subtitle is very helpful: *The Extensions of Man*. The student of media is the technology. It's what we make. That's not us. And they extend our senses. This microphone can extend my voice, and it extends our brain. His subtitle explains the positives where it makes us... We could do more; we have more power. But it also can do the opposite. His other phrasing is they also amputate us in a way; we lose our own senses.

[19:09] **Melody:** That's interesting, because this brings us back to this idea of legibility too. In a way, it's the tools anthropomorphize or something or make legible. They're extensions of ourselves, but... Again, maybe calling back to this whole idea of control too. We want to have a sense of... we want to make everything tangible; we can understand it. It's scary to us to exist in more of a void. And if we can imagine... If now we have a framework of the LLM to talk about our human feelings or, I don't know, scary things that we don't have control over, we want to lean... It's a crutch, essentially. I don't know.

#### Technological Coping

[19:58] **Henry:** Yes, I agree. Technology as a whole feels like a coping mechanism to not be able to deal with our problems. I feel that way. I don't want to feel negative emotions, and I'll turn to whatever you want to use to cope rather than facing it. It's funny that we create technology and lose spiritual technology, if I want to use that word. It's prayer and Sabbath and all these things that let us face our demons or our problems, because we're giving up the things of the world.

[20:38] **Melody:** I really like that contrast. That's something we need to amplify more. It's this idea that technology gives us this illusion of control, and we're continuing to move in that direction. But much of being a Christian is about the giving up of control. It's all about humility. It's all about lifting up to God. That is the scariest and hardest thing to do. Prayer is the most obvious example of this. With AI, how much more are we going to turn to asking ChatGPT what we should do in this situation with our parents versus lifting up the issue to God? I personally am already doing that probably more than I should. I really see these concepts in context of each other, because it signifies much of where we're headed as a society. We're speeding towards more control and wanting more anxiety, more... what is it? Ah, gosh, this idea that we have control over all these things, when Christianity and what God is reminding us is that we don't, and that we are best left off leaving it up to Him and trusting in Him.

[21:37] **Henry:** And maybe they're doing it too, your parents. If we don't have control, then He will reveal Himself eventually, meaning that whatever we put our trust in, which I'll say is where we're putting our hope, that is our god. The thing that ultimately gives us a reason to wake up every day. If it's not God, it's going to fail. That's what happens when I realize I've been worshiping another god. It could be as simple as one day it stops working because it's down. I realized that I was relying on it too much. That's the essence of idolatry.

#### Deliberate Choices

[22:56] **Melody:** 100%. This brings to mind something we touched upon briefly. This is a very nuanced and sensitive topic, but the idea of even IVF or technology around fertility and pregnancy. There are some times when I start to think, when are you jumping through too many hoops? When is it too much? Obviously, you want everyone to have the opportunity to be parents. But, it's a very controversial thing to say. In general, to your point, when do we start to idolize some of these things? And when are we using technology to enable us towards things that maybe we have to approach with an open hand?

[23:57] **Henry:** No, I don't want my default to be a yes to using some technology. And I don't want to be Amish, but their philosophy is that they vote as a community what is worth using and what's not. That's the way it works, not that they wholesale remove all technology. Of course, that's not necessarily how it plays out in practice, but the ideal of that is helpful. When the default is either/or, it means you're not really thinking about the implications of what we're making. Again, that doesn't mean that we shouldn't pursue IVF or whatever it is.

#### Unexamined Accelerationism

[24:37] **Melody:** It's crazy that it's being accepted. No one's talking about it. Literally, the other day at dinner, people were talking about cloning dogs, and now I'm thinking, "Isn't that what Gattaca...?" Are we not racing towards this path? Because, again, it's the whole "because we can and that technology is a net good." I definitely fall into that sometimes, even with the AI stuff. I think, "Yeah, it's inevitable. We're going to..." I've definitely used that argument before. But I'm still wary to say that about artificial wombs and us racing down, and cloning non-sentient humans to be replacement organs. Where do you stand on that in this accelerationist argument for AI? What do you feel is going to happen? We talked about how, at least for me, I'm not afraid of the sentience piece. I am curious what people are nervous about. The picture they paint is that one day the AI will become sentient and try to trick us, take over the world, and eradicate humans. Is that what people are? I don't know. Suddenly, we're in a simulation, da-da-da. I don't know. 

[26:05] **Henry:** There's a huge spectrum. That is one aspect of it. Anything's possible, but I don't think that matters to me, meaning that other things will happen that could also cause the end of the world that would happen before that happens, if that makes sense. I said about how it's already changing our dependence on it and changing our relationship to other people. I feel that already leads to a lot of bad outcomes, because that will happen earlier than our fear that it's going to take over the world and then everything gets bombed or something. That, to me, if that is possible and can happen, then that is a concern. But along the way, there are plenty of bad things that will happen. Why are we...? And I know there's this, especially in the EA circle, it's all about the doomsday scenario. If something has a 1% or .00001% chance, but it will destroy everything, then we need to put all of our resources into it. I feel you can co-opt a lot of people's careers and lives to get them to think about that, but we don't even know how to... It's funny. We don't even know how to care for our family, and now we're concerned about this? There are many levels before that. You think, "We don't..." As I said, I don't even know how to cope with someone getting mad at me, and that's simple. And then now we're saying, "Oh, the AI's going to take over the world." We don't even know how to take criticism or forgive people.

#### The Proximity of Care

[28:01] **Melody:** The loneliness epidemic. I completely agree, and this is a social thing we've dealt with where we love the idea of a grand cause to work towards versus being kind to our neighbor. We will get worked up for all these social causes, whether you're on the left or the right. We want to go on missions. I'm a strong proponent of missions, but you need to be serving your church, serving the neighbor next door. Do you even greet the people around you? Do you get up for the grandmother on the subway? If you can't even extend this level of kindness, why are we even thinking about the greater thing?

[28:59] **Henry:** There is an assumption with that: there are concentric circles of care. Not everyone agrees with that. Some would say it's more of a globalist view that everyone is equal. I think most people do care about proximity, and it's not an arbitrary value. It's also easier to love people that are really far away because you don't have to experience the pains of being in a relationship with a real community. You give them money, which are necessary things, but it almost makes you... Again, you can hide behind that in a way. It makes you feel good, "Oh, I helped all these people." And then, the person right next to you... There's this weird cognitive dissonance that gets created when we care about people in the abstract. Everyone has different levels of, you could say, power or influence to be able to do that. But it's interesting that most regular people still feel this need to help everybody. If we all helped our neighbor... but that's too hard because we have to change the culture. It's funny. Our reason to make all this technology is because we're unable to have real community. We scale our lack of character and humanity by scaling technology instead of ourselves. But it's funny that that's more impossible to us because we don't have faith in ourselves and in each other, in people. That's why we're relying on robots or AI to do it for us, because they will do what we want them to do.

[30:28] **Melody:** Yes. The stuff doesn't scale to do the kind things for your neighbors. But what you're saying is that if we do encourage that as a culture, that is what can scale.

#### Self-Sufficiency and Vulnerability

[30:56] **Melody:** We don't want to be uncomfortable. But what were you going to say? Sorry. Ugh. I feel that's heartbreaking. But to your point, all of this points to this idea that we don't want to be... Even our lunch conversation was about this, I feel. We all want to be super self-sufficient. We want technology to take care of everything for us, and this technology gives more people access towards this self-sufficiency. I feel that's what it is. And I feel we're going to keep butting up against this. I never really thought about this contrast until this conversation. But it's that technology gives us this façade of self-sufficiency. It's really the thing that encourages a stronger fabric of society is being willing to be vulnerable, being willing to not be self-sufficient, being willing to deal with uncomfortable feelings where we're brushing up against each other. We're sad, we hurt each other. But it's that's what we need to lean into more. And technology maybe abstracts all of that away from us, or gives us the idea that we can abstract it all away from us.

[32:29] **Henry:** Yes, it does. And it works too, to some degree. That's the... It's effective and it works. I think that's the problem. Is when we say it makes us feel self-sufficient, it doesn't mean that we need it. We both work in tech. The point is that you cannot ultimately be self-sufficient, meaning that you can't rely on it entirely. It's clearly helpful, and we need it, and I'm working on it. But at the very core of it, that's not what gives me hope that we're going to solve any of this because we made some new app.

#### Engineering Out Discomfort

[33:08] **Melody:** How do you think we ended up here? As a society, one clear example of this too is we don't see graveyards anymore. Back in the day, graveyards were near the church, and we would encounter death on a more regular basis. We've almost sanitized our society and our lives because we desperately want no sadness or discomfort; we don't want to deal with death. We have these very sanitary lives, and we're saying technology is enabling us to live those kinds of extreme... it's extreme convenience, extreme... I don't know, only happiness. Happiness only. Do you get what I'm trying to say?

[33:59] **Henry:** Yes, I understand. Illich has a whole book called *Medical Nemesis* criticizing hospitals and the whole industry. His phrase is, "From womb to tomb, the doctor has control over your life." You were born in the hospital. You die in the hospital. Now, some of us don't even see our parents or grandparents when they're dying, which is crazy. Again, hospitals have done a lot of good, but he's pointing out that there are clearly some issues around that. The graveyard thing is interesting. Why do you have to... When someone dies, why do they have to pay $50,000 for the funeral? That's insane too. Why is there even a professionalized industry to do that? You could say the same thing about life. It's hard to escape because it's the default. To not do that would be weird, having a baby in the hospital or dying in the hospital. To use that—it's funny—not for the career, but for your life.

[35:17] **Melody:** To follow the path, we were saying. These are parallels. It's all about control and this guise of expectation that modern society has written out for us. A job career and job path was not something that existed 200 years ago, a laptop job. We expect more things with fewer downsides.

#### Hidden Labor

[35:43] **Henry:** Many things are very recent, which is interesting. Not being able to understand history. We have a lot of things we expect now. Sometimes technology or society hides bad things. When you live in a city, you use the subway, you see the trash all over the street. As you said, the graveyard was next to the church, everyone saw it. But then we hide everything. We pay for someone else; all our trash is gone. You don't see... Even AI, the interface we see is ChatGPT, but it was trained on all the data on the internet. They also had to pay, or not pay, lots of people to label data: Yes or no, yes or... Right or wrong. That's all manual labor. Facebook? They have people who all got PTSD from figuring out whether these things are good or bad. And it's, oh, it's all AI, it's automated. But it was on the backs of all these people who have to deal with that. That's everywhere.

[36:48] **Melody:** It's something we'll look back on and see as the cruelty of... It's a different inhumanity that coal miners had to go through to produce energy. In the same way, these data labelers were subjected to horrendous conditions to give us a clean, sanitized internet, or sanitized data that we can use for our AI.

[37:11] **Henry:** You're mentioning what it means to be a stay-at-home parent. I really like Illich's concept of what he calls shadow work: work that is unpaid, that is required in order to consume some good that you buy. One example is the self-checkout line. When you buy something at a store, that was someone's job to do that. Now we're doing... You could say it's free labor, for the convenience of us being able to get out. The easiest one is commuting. You don't get paid for commuting, but it's part of your job. There's a lot of labor, real work, that we all have to do in order to function in society. Usually, an answer to that is, "Oh, we should pay people for it." It's funny that the answer is always... Wait, the other one is childcare. He thinks it works because the amount of money in the shadow economy is more than we have. You cannot measure how much money that is. You're always going to pay them too little.

[38:17] **Melody:** I feel that this question has been floating through my mind since the last topic we were talking about, but how did we get here as a society? Is it capitalism? Is everything broken down into some economic value, and we've sliced and diced every single service—childcare, hospital, school? And that it breaks down the social fabric? When it is important, there's an intangible value to serving each other in ways that goes beyond any economic value you can boil it down to.

[39:23] **Henry:** Because we cannot explain it doesn't mean it's not there. It's easy to say, "Well, you can't measure it." That's a framing already—having to be able to measure it or convert it into money. The value of something based on what you exchange is the monetary value, but there's the utility of it. There is a lot of worth in cooking for yourself, not because it might be cheaper, but how do you measure the love you have for your children or your friends? I really like the idea that technology can be an act of love too. I love studying this essay called *An App Can Be a Home-Cooked Meal*. This writer, Robin Sloan, he's not a programmer, but he wrote an app for his family. It's a social media app for people. He never has to update it. There's no login. They use it every day for the last four years. He wrote it in a weekend. Not that no one's ever done that before, but it's helpful to think, "Oh, I don't have to make a Facebook."

[40:26] **Melody:** I love that. To your point, I feel we lose something by trying to boil everything down to some economic value. This points to this whole idea of, again, our culture's obsession with control. Once you can put a number to it, we feel we have some control. We can measure it, we can improve it. What's interesting in this era of AI and vibe coding, as you want to call it, we can now... Technology can now maybe be divorced from only the big players who have enough money and the right incentive structures to build technology tools. Now more people have the tools to be able to do what you mentioned. We can use technology as a home-cooked meal.

[41:16] **Henry:** There's always been this dream of what people have called end-user programming, where the users themselves can code. You don't need to know how to program, and it's true that LLMs help with that. Sometimes it feels easier to point out the bad, and if we are in the industry, then we can point out examples of how you can use it.

[41:31] **Melody:** It's interesting. With any technology, it enables lots of good and lots of bad. At a super high level, what are the principles? What's the culture we want to encourage around the use of all of this? How do we use it to amplify the good, how we can serve each other using technology, serve each other better, rather than having it completely replace all of our interactions with our community and that kind of thing?

#### Finitude

[42:26] **Henry:** We were talking about how technology is legible; it makes things easier to measure. Another concept from Illich is this idea of what is valuable, which is what is good. Value is measurable, but that's what makes it subjective, which is ironic. You would think the thing you can measure is the objective thing, but the good is objective because it involves limitation. It involves acknowledging that too much of something can be bad and too little of something can be bad. There's the golden mean scenario. That relates to what it means to be created as a creature. We are not God. We should acknowledge who we are as limited, finite beings, and we can embrace that, and that is good. There's a book called *Small Is Beautiful*, which refers to this too. I don't know. The most interesting or meaningful parts of my life have always been things that are non-measurable. The desire for it is an issue too. When we talk about friendship and things like that, and we all know that, measuring friendship by how many likes you have, we know that there's something inherently bad about that. If it feels like vibes, then we think, "Oh, that's not... I'm being too emotional." It's weird; we don't trust our intuition a lot. And I don't know. Maybe we feel smarter because you have a rationalist way of thinking about things. Cool. Awesome. Thanks.

[43:19] **Melody:** It's being honest about our state. Somehow, we're all heading towards vibes everything—it's vibes coding, it's vibes design, it's vibes... Maybe we're realizing that it isn't... Thanks, Henry. I feel I have much to think about from here. My main takeaway from this was the idea that technology gives you more control, and much of a functional, healthy society is not that, not focusing on optimizing for control and everything.

[44:51] **Henry:** Maybe that comes because of where we're coming from; we know that we don't control because we believe in God. If you don't believe that, what else is there left? You should be pursuing control, which is pursuing power. Jesus chooses to become powerless on the cross. But then ironically, in his powerlessness, he shows his real power—resurrection and everything.

[45:24] **Melody:** What I like about that is that it amplifies this contrast again around our... Maybe what it is is, where does our angsty desire for control come from? It is an anxiety. It is a 'do not worry,' and we're worrying, and that worry comes out and manifests itself in our idea of control. What we were saying at the very beginning is that this life, this set path, is in our control, but it's all a facade of the world, all an illusion. The really the only thing we can hope in is in Christ.